digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139746500532480 [label="
 (1, 4)" fillcolor=darkolivegreen1]
	139746514479952 [label=AddmmBackward0]
	139746514480048 -> 139746514479952
	139746500531920 [label="fnn_layer2.bias
 (4)" fillcolor=lightblue]
	139746500531920 -> 139746514480048
	139746514480048 [label=AccumulateGrad]
	139746514480000 -> 139746514479952
	139746514480000 [label=ReluBackward0]
	139746514479712 -> 139746514480000
	139746514479712 [label=AddmmBackward0]
	139746514480192 -> 139746514479712
	139746500531760 [label="fnn_layer1.bias
 (20)" fillcolor=lightblue]
	139746500531760 -> 139746514480192
	139746514480192 [label=AccumulateGrad]
	139746514480144 -> 139746514479712
	139746514480144 [label=CatBackward0]
	139746514480288 -> 139746514480144
	139746514480288 [label=SelectBackward0]
	139746514480480 -> 139746514480288
	139746514480480 [label=SelectBackward0]
	139746514480576 -> 139746514480480
	139746514480576 [label=SliceBackward0]
	139746514480672 -> 139746514480576
	139746514480672 [label=SliceBackward0]
	139746514480768 -> 139746514480672
	139746514480768 [label=ReluBackward0]
	139746514480864 -> 139746514480768
	139746514480864 [label=ConvolutionBackward0]
	139746514480960 -> 139746514480864
	139746514480960 [label=ReluBackward0]
	139746514481104 -> 139746514480960
	139746514481104 [label=ConvolutionBackward0]
	139746500599968 -> 139746514481104
	139746500599968 [label=ReluBackward0]
	139746500600160 -> 139746500599968
	139746500600160 [label=ConvolutionBackward0]
	139746500600304 -> 139746500600160
	139746500531280 [label="cnn_layer1.weight
 (15, 1, 3, 3)" fillcolor=lightblue]
	139746500531280 -> 139746500600304
	139746500600304 [label=AccumulateGrad]
	139746500600256 -> 139746500600160
	139746500531360 [label="cnn_layer1.bias
 (15)" fillcolor=lightblue]
	139746500531360 -> 139746500600256
	139746500600256 [label=AccumulateGrad]
	139746500599920 -> 139746514481104
	139746500531440 [label="cnn_layer2.weight
 (15, 15, 7, 7)" fillcolor=lightblue]
	139746500531440 -> 139746500599920
	139746500599920 [label=AccumulateGrad]
	139746500599872 -> 139746514481104
	139746500531520 [label="cnn_layer2.bias
 (15)" fillcolor=lightblue]
	139746500531520 -> 139746500599872
	139746500599872 [label=AccumulateGrad]
	139746514480912 -> 139746514480864
	139746500531600 [label="cnn_layer3.weight
 (15, 15, 2, 2)" fillcolor=lightblue]
	139746500531600 -> 139746514480912
	139746514480912 [label=AccumulateGrad]
	139746514480384 -> 139746514480864
	139746500531680 [label="cnn_layer3.bias
 (15)" fillcolor=lightblue]
	139746500531680 -> 139746514480384
	139746514480384 [label=AccumulateGrad]
	139746514480096 -> 139746514479712
	139746514480096 [label=TBackward0]
	139746514480528 -> 139746514480096
	139746500531200 [label="fnn_layer1.weight
 (20, 19)" fillcolor=lightblue]
	139746500531200 -> 139746514480528
	139746514480528 [label=AccumulateGrad]
	139746514479904 -> 139746514479952
	139746514479904 [label=TBackward0]
	139746514480432 -> 139746514479904
	139746500531840 [label="fnn_layer2.weight
 (4, 20)" fillcolor=lightblue]
	139746500531840 -> 139746514480432
	139746514480432 [label=AccumulateGrad]
	139746514479952 -> 139746500532480
}
